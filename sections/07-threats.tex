\chapter{Threats to Validity}
\label{sec:limitations-threats}

In this section, we discuss the threats to validity, including internal, external, construct, and conclusion validity.

\textbf{Conclusion validity}. Threats in this category
impact the relationship between treatment and outcome. The biggest threat to the conclusion validity was the statistical significance obtained in the calculation of agreement using the technique proposed by Joseph L. Fleiss \cite{fleiss1971measuring}. Given the time constraints to conduct the research, it was not possible to prospect a sufficient number of subjects (participants) in order to create a satisfactory database, although every effort was made to publicize and expand the number of participants to the experiment. Thus, despite the mitigation efforts, for a significant part of the agreement scores established in \textbf{RQ1}, the expected statistical significance was not achieved.

\textbf{Internal validity.} Threats refer to the factors that may have influenced our study.  First, our concern when designing the experiment was to make it easy to use and that its duration occurs in the shortest possible time, to prevent the experiment from being boring. Although there was a concern to mitigate this issue, including a brief pilot experimentation, the duration of each participation was approximately 60 minutes on average. Given the amount of time that or experiment lasts, we can assume that, after a certain point, the participants felt tired or unmotivated, directly affecting the quality of the information provided.

Second, we are aware that social interactions can be another threatening factor to the validity of the results: due to the fact that the experiment execution was not controlled, the participants who performed the experiment had time to interact with the applicants. Therefore, we assume that this social interaction can cause changes in the behavior of the candidate participants during the execution of the experiment. However, we detected that this situation is a necessary trade-off: we needed to create a web experiment that could reach the largest possible number of software engineering professionals in exchange for exposure to the threats resulting from the interaction between people.

\textbf{External Validity.} The threats here concern the degree to which the findings can be generalized to the wider classes of subjects. Our study is based on an experiment published on the internet to reach as many volunteers as possible. Due to the number of participants that committed our research instrument, less than expected, we are aware that our research may be subject to the problem of representativeness, which may affect the generalization of the results. Possible mitigation to this problem would be to substantially increase the number of participants and make our experiment reach different profiles of professionals, which we aim for further works. 

As for the number of types of code smells, we chose 4 out of 20 possible types cataloged by Fowler \cite{fowler1999refactoring}. This small sample was necessary to make the experiment executable within a reasonable time. To mitigate possible threats to the generalization validity, we focus our choice on how developers recognize each type of code smell in terms of perceptiveness and level of agreement pointed out by previous studies \cite{palomba2014they, hozano2018you}, going from the most perceived smell to the least as a criterion of choice. 


\textbf{Construct Validity.} This is an uncontrolled experiment, which raises some concerns. The most important is that which affects the dedicated effort to solve tasks, as discussed in RQ2. Without the effective control of the participants' activities, it is not possible to accurately measure the time actually spent on completing the activities. As a result, eventual dispersions by the participants may overestimate the completion time of the activities, impacting the result of RQ2.



